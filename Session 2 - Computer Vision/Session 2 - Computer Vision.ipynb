{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 (remove unwanted object) (~10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2# as apple_pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_telea = cv2.INPAINT_TELEA\n",
    "flags_ns = cv2.INPAINT_NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try both 1a and 1b\n",
    "image = cv2.imread(r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\Example 1b.jpg')\n",
    "mask = cv2.imread(r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\Example 1b - Copy.jpg')\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "output = cv2.inpaint(image, mask, 10, flags=flags_telea)\n",
    "\n",
    "cv2.imshow('Image', image)\n",
    "cv2.imshow('Mask', mask)\n",
    "cv2.imshow('Output', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teaching points\n",
    "# how it relates to daily work\n",
    "# pip install --user --trusted-host files.pythonhosted.org --trusted-host pypi.org xxxx\n",
    "# simplicity of code and power of libraries\n",
    "# coding structure: import, define, process\n",
    "# explain each line doing what\n",
    "# explain what's use of .\n",
    "# shift tab to read doc\n",
    "# how to change variables in code\n",
    "# tab to open available functions\n",
    "# good practice of define variables ahead\n",
    "# comment out whole line or # partially\n",
    "# markdown\n",
    "# how to make code more readable like writing comprehension\n",
    "# order of running code / lines\n",
    "# global and local variables\n",
    "# import as\n",
    "# shortcut keys to run all, run above, run below, terminate\n",
    "# inspect array of image to relate what was learnt in theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 (compare images) (~20 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "from skimage.metrics import structural_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download poppler https://github.com/oschwartz10612/poppler-windows/releases/\n",
    "# unzip\n",
    "img1 = convert_from_path(r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\Example 2.pdf',\n",
    "                        poppler_path = r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\poppler-21.03.0\\Library\\bin')\n",
    "img1 = np.asarray(img1[0])\n",
    "\n",
    "img2 = convert_from_path(r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\Example 2 - Copy.pdf',\n",
    "                        poppler_path = r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\poppler-21.03.0\\Library\\bin')\n",
    "img2 = np.asarray(img2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dimension = 1 #25\n",
    "\n",
    "img1 = cv2.resize(img1, (0,0), fx=0.5, fy=0.5)\n",
    "img2 = cv2.resize(img2, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "img1_bw = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_bw = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "score, diff = structural_similarity(img1_bw, img2_bw, full=True)\n",
    "diff = (diff * 255).astype(\"uint8\")\n",
    "thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "for cnt in cnts:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    if w > min_dimension and h > min_dimension:\n",
    "        cv2.rectangle(img1, (x,y), (x+w,y+h), (0,0,255), 2)\n",
    "#         cv2.circle(img1, (x,y), 10, (0,0,255), 2)\n",
    "\n",
    "cv2.imshow('img1',img1)\n",
    "cv2.imshow('img2',img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teaching points\n",
    "# explain each line doing what\n",
    "# try convert BGR to RGB\n",
    "# change colour of rectangular box\n",
    "# change file path\n",
    "# read .circle and see what can be changed\n",
    "# compare rectangle and circle\n",
    "# change min dimension for better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 (incomplete panorama) (~30 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = str(r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\photo set 2')\n",
    "output_path = str(r'C:\\Users\\TON93824\\Mott MacDonald\\Automation & Computational Design - Python\\AUS\\2021\\Session 2 - Computer Vision\\photo set 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images(input_path)))\n",
    "images = []\n",
    "for i in imagePaths:\n",
    "    image = cv2.imread(i)\n",
    "    image = cv2.resize(image, (0,0), fx=0.25, fy=0.25) # use this line if cv::OutOfMemoryError\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',cv2.Stitcher_create().stitch(images)[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(output_path + str('\\\\') + str('done.jpg'), cv2.Stitcher_create().stitch(images)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teaching points\n",
    "# how to use list and append\n",
    "# for loop\n",
    "# try inspect some images from the list appended\n",
    "# learn list length\n",
    "# learn resize\n",
    "# simple one line can stitch, learn read library doc\n",
    "# learn write image\n",
    "# learn about file path, string, int, float\n",
    "# learn if statement\n",
    "# multiple output from one line\n",
    "# time library, %%time\n",
    "# appreciate the wealth of library and research papers behind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spare materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from pyimagesearch example\n",
    "# instead of using photoshop, can also use python to achieve much better result\n",
    "# https://www.pyimagesearch.com/2020/05/18/image-inpainting-with-opencv-and-python/\n",
    "# replace with example image and demonstrate\n",
    "# illustrate same flow, import, define, process\n",
    "# change one line can feed from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0 160] [-100, -30, 90] [100, 30, 230]\n",
      "[19 49 42] [-81, 19, -28] [119, 79, 112]\n",
      "[170   5 142] [70, -25, 72] [270, 35, 212]\n",
      "[173   7 145] [73, -23, 75] [273, 37, 215]\n",
      "[100 161  84] [0, 131, 14] [200, 191, 154]\n",
      "[ 98 154  88] [-2, 124, 18] [198, 184, 158]\n",
      "[105 197  53] [5, 167, -17] [205, 227, 123]\n",
      "[  0   0 171] [-100, -30, 101] [100, 30, 241]\n",
      "[ 75   3 183] [-25, -27, 113] [175, 33, 253]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "hsv_buffer_H = 100 # 10\n",
    "hsv_buffer_S = 30 # 10\n",
    "hsv_buffer_V = 70 # 40\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "\n",
    "# Inspect background array to identify max / min for webcam input\n",
    "image_hsv = None   # global\n",
    "pixel = (20,60,80) # initial seed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# mouse callback function\n",
    "def pick_color(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pixel = image_hsv[y,x]\n",
    "\n",
    "        upper =  np.array([pixel[0] + hsv_buffer_H, pixel[1] + hsv_buffer_S, pixel[2] + hsv_buffer_V])\n",
    "        lower =  np.array([pixel[0] - hsv_buffer_H, pixel[1] - hsv_buffer_S, pixel[2] - hsv_buffer_V])\n",
    "        print(pixel, lower.tolist(), upper.tolist())\n",
    "\n",
    "        image_mask = cv2.inRange(image_hsv,lower,upper)\n",
    "        cv2.imshow(\"mask\",image_mask)\n",
    "\n",
    "import sys\n",
    "# global image_hsv, pixel # so we can use it in mouse callback\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "#     frame = image # in case want certain pic instead of webcam\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "\n",
    "    ## NEW ##\n",
    "    cv2.namedWindow('hsv')\n",
    "    cv2.setMouseCallback('hsv', pick_color)\n",
    "\n",
    "    # now click into the hsv img , and look at values:\n",
    "    image_hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow(\"hsv\",image_hsv)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# green curtain example\n",
    "# change HSV boundaries manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_img = cv2.imread(r'Z:\\python\\070. inpaint\\opera house.jpg')\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    lower_bound = np.array([-80, -17, 49] ) # manual input\n",
    "    upper_bound = np.array([120, 43, 189]) # manual input\n",
    "\n",
    "    mask = cv2.inRange(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), lower_bound, upper_bound)\n",
    "    \n",
    "    background_img = cv2.resize(background_img, (frame.shape[1],frame.shape[0]))\n",
    "    roi = background_img[0:frame.shape[0], 0:frame.shape[1]]\n",
    "    cleaned_background_img = cv2.bitwise_and(roi, roi, mask = mask) # change to image_mask_dilate / erode as required\n",
    "    \n",
    "    cleaned_foreground_img = cv2.bitwise_and(frame, frame, mask = cv2.bitwise_not(mask)) # reverse of masked image # change to image_mask_dilate / erode as required\n",
    "    combined_img = cv2.add(cleaned_background_img, cleaned_foreground_img)\n",
    "\n",
    "    cv2.imshow(\"combined_img\",combined_img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
